{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "# import tensorflow as tf\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import io\n",
    "from easydict import EasyDict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "DATASET_PATH =  r'C:\\Users\\khanz\\PycharmProjects\\inno_ds\\final_project\\data\\merged_data'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html\n",
    "ROOT_DIR = 'C:/Users/khanz/PycharmProjects/inno_ds/final_project/data/102flowers'\n",
    "flowers102_cfg = EasyDict()\n",
    "flowers102_cfg.labels_file = os.path.join(ROOT_DIR, 'imagelabels.mat')\n",
    "flowers102_cfg.images_path = os.path.join(ROOT_DIR, 'jpg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/how-to-read-tfrecords-files-in-pytorch-72763786743f\n",
    "ROOT_DIR = 'C:/Users/khanz/PycharmProjects/inno_ds/final_project/data/tpu-getting-started'\n",
    "flowers_tpu_cfg = EasyDict()\n",
    "flowers_tpu_cfg.images_path = os.path.join(ROOT_DIR, 'tfrecords-jpeg-331x331')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/alxmamaev/flowers-recognition\n",
    "ROOT_DIR = 'C:/Users/khanz/PycharmProjects/inno_ds/final_project/data/Flowers Recognition'\n",
    "flowers_rec_cfg = EasyDict()\n",
    "flowers_rec_cfg.images_path = os.path.join(ROOT_DIR, 'flowers')\n",
    "flowers_rec_cfg.categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка датасетов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def merge_data(dataset_cfgs, path_to_save):\n",
    "    # сливание трех датасетов в один, формирование новой нумерации классов\n",
    "    merged_df = pd.DataFrame()\n",
    "    start_class_num = 0\n",
    "    for dataset_name, cfg in dataset_cfgs.items():\n",
    "        merged_data_path = os.path.join(path_to_save, dataset_name)\n",
    "        if not os.path.exists(merged_data_path):\n",
    "            os.mkdir(merged_data_path)\n",
    "        df = getattr(sys.modules[__name__], f'{dataset_name}_preprocess')(cfg, merged_data_path)\n",
    "        labels = np.unique(df['label'])\n",
    "        label2global = {l: i + start_class_num for i, l in enumerate(labels)}\n",
    "        df['label'] = df['label'].map(label2global)\n",
    "        start_class_num = start_class_num + len(labels)\n",
    "\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "    merged_df.to_csv(os.path.join(path_to_save, 'annotation.csv'), index=False)\n",
    "\n",
    "\n",
    "def flowers102_preprocess(cfg, path_to_save):\n",
    "    labels = sio.loadmat(cfg.labels_file)['labels'].flatten()\n",
    "    image_paths = []\n",
    "    for path in tqdm(os.listdir(cfg.images_path), 'Copy files'):\n",
    "        src = os.path.join(cfg.images_path, path)\n",
    "        dst = os.path.join(path_to_save, path)\n",
    "\n",
    "        if os.path.exists(dst):\n",
    "            print(path)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "        image_paths.append('/'.join(dst.split('\\\\')[-2:]))\n",
    "\n",
    "    return pd.DataFrame(data={'path': image_paths, 'label': labels})\n",
    "\n",
    "\n",
    "def flowers_rec_preprocess(cfg, path_to_save):\n",
    "    image_paths, labels = [], []\n",
    "    for i, cat in enumerate(cfg.categories):\n",
    "        for path in tqdm(os.listdir(os.path.join(cfg.images_path, cat)), f'category - {cat}'):\n",
    "            src = os.path.join(cfg.images_path, cat, path)\n",
    "            dst = os.path.join(path_to_save, path)\n",
    "\n",
    "            if os.path.exists(dst):\n",
    "                print(path)\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "            image_paths.append('/'.join(dst.split('\\\\')[-2:]))\n",
    "            labels.append(i)\n",
    "\n",
    "    return pd.DataFrame(data={'path': image_paths, 'label': labels})\n",
    "\n",
    "\n",
    "def flowers_tpu_preprocess(cfg, path_to_save):\n",
    "    train_feature_description = {\n",
    "        'class': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    def _parse_image_function(example_proto):\n",
    "        return tf.io.parse_single_example(example_proto, train_feature_description)\n",
    "\n",
    "    image_paths, labels = [], []\n",
    "    for data_type in ['train', 'val']:\n",
    "        files = glob.glob(cfg.images_path + f'/{data_type}/*.tfrec')\n",
    "        for i in tqdm(files, desc=f'{data_type}'):\n",
    "            train_image_dataset = tf.data.TFRecordDataset(i)\n",
    "            train_image_dataset = train_image_dataset.map(_parse_image_function)\n",
    "            ids = [str(id_features['id'].numpy())[2:-1] for id_features in train_image_dataset]\n",
    "            labels.extend([int(class_features['class'].numpy()) for class_features in train_image_dataset])\n",
    "            images = [image_features['image'].numpy() for image_features in train_image_dataset]\n",
    "            for _id, img in zip(ids, images):\n",
    "                dst = os.path.join(path_to_save, f\"{_id}.jpeg\")\n",
    "                img = cv2.cvtColor(np.asarray(Image.open(io.BytesIO(img))), cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(dst, img)\n",
    "                image_paths.append('/'.join(dst.split('\\\\')[-2:]))\n",
    "\n",
    "    return pd.DataFrame(data={'path': image_paths, 'label': labels})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_configs = {\n",
    "    'flowers_tpu': flowers_tpu_cfg,\n",
    "    'flowers_rec': flowers_rec_cfg,\n",
    "    'flowers102': flowers102_cfg\n",
    "}\n",
    "merge_data(dataset_configs, DATASET_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Объединение дубликатов по классам"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "annot = pd.read_csv(os.path.join(DATASET_PATH, 'annotation.csv'))\n",
    "ignore_classes = [4, 113]\n",
    "\n",
    "# map для 102flowers и flowers_rec\n",
    "map_dict = {i: i for i in np.unique(annot['label'])}\n",
    "map_dict.update({107: 162, 105: 158, 104: 157, 106: 182})\n",
    "\n",
    "new_annot = annot.copy()\n",
    "new_annot['label'] = annot['label'].map(map_dict)\n",
    "\n",
    "map_dict = {i: i for i in np.unique(new_annot['label'])}\n",
    "\n",
    "classes_counts = new_annot['label'].value_counts()\n",
    "\n",
    "# объединение 102flowers и flowers_tpu\n",
    "combine_classes = [(i, i + 109) for i in np.arange(0, 102) if i not in ignore_classes]\n",
    "combine_classes += [(102, 108)]\n",
    "dropped_classes = []\n",
    "for current_class, another_class in combine_classes:\n",
    "    current_class_len = classes_counts[current_class]\n",
    "    another_class_len = classes_counts[another_class]\n",
    "\n",
    "    if current_class_len > another_class_len:\n",
    "        dropped_classes.append(another_class)\n",
    "    else:\n",
    "        dropped_classes.append(current_class)\n",
    "new_annot = new_annot[~new_annot['label'].isin(dropped_classes)]\n",
    "map_dict = {cl: i for i, cl in enumerate(np.unique(new_annot['label']))}\n",
    "new_annot['label'] = new_annot['label'].map(map_dict)\n",
    "new_annot.to_csv(os.path.join(DATASET_PATH, 'annotation_updated.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Разбиение данных на тестовую и обучающую выборки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def split_data(annot_df, part=0.40):\n",
    "    classes, counts = np.unique(annot_df['label'], return_counts=True)\n",
    "    test_len = int(len(classes) * part)\n",
    "    test_classes = np.random.choice(classes, test_len, replace=False)\n",
    "    train_classes = np.setdiff1d(classes, test_classes)\n",
    "\n",
    "    test_classes, counts = np.unique(annot_df[annot_df['label'].isin(test_classes)]['label'], return_counts=True)\n",
    "    print(len(test_classes), np.sum(counts))\n",
    "    print(test_classes)\n",
    "    print(counts)\n",
    "\n",
    "    train_classes, counts = np.unique(annot_df[annot_df['label'].isin(train_classes)]['label'], return_counts=True)\n",
    "    print(len(train_classes), np.sum(counts))\n",
    "\n",
    "    return train_classes, test_classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 8687\n",
      "[  0   3   4   6   8  10  17  18  22  23  24  25  29  30  32  33  41  43\n",
      "  48  49  51  64  66  68  69  73  75  78  79  80  81  82  84  85  87  89\n",
      "  95  96  98 101 102 103]\n",
      "[ 351  136  112  176  340  116   94  124  337  259  135  148  336  121\n",
      "  177  216  173  155  169  164  959   91   40   45   46  108   41   40\n",
      "  813 1144  794   71  114   67   50   52   63   58   82   63   49   58]\n",
      "63 10724\n"
     ]
    }
   ],
   "source": [
    "annot = pd.read_csv(os.path.join(DATASET_PATH, 'annotation_updated.csv'))\n",
    "train_classes, test_classes = split_data(annot)\n",
    "annot_train = annot[annot['label'].isin(train_classes)].reset_index()[['path', 'label']]\n",
    "annot_test = annot[annot['label'].isin(test_classes)].reset_index()[['path', 'label']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "annot_train.to_csv(os.path.join(DATASET_PATH, 'annotation_train.csv'), index=False)\n",
    "annot_test.to_csv(os.path.join(DATASET_PATH, 'annotation_test_all.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка query и retrieval set для тестовой выборки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "annot_test = pd.read_csv(os.path.join(DATASET_PATH, 'annotation_test_all.csv'))\n",
    "\n",
    "classes, counts = np.unique(annot_test['label'], return_counts=True)\n",
    "\n",
    "img_paths, labels = [], []\n",
    "new_annot = pd.DataFrame()\n",
    "for cl, c in zip(classes, counts):\n",
    "    s = min(c, 8)\n",
    "    indices = np.random.choice(annot_test[annot_test['label'] == cl].index.tolist(), size=s)\n",
    "    new_annot = new_annot.append(annot_test.loc[indices], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_annot.to_csv(os.path.join(DATASET_PATH, 'annotation_test.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# сохранение в одну папку\n",
    "annot = pd.read_csv(os.path.join(DATASET_PATH, 'annotation_test.csv'))\n",
    "for i, row in annot.iterrows():\n",
    "    src = os.path.join(DATASET_PATH, row['path'])\n",
    "    dst = os.path.join(DATASET_PATH, 'test_set', f\"{row['label']}_{i}.jpeg\")\n",
    "    shutil.copyfile(src, dst)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "old_annot = pd.read_csv(os.path.join(DATASET_PATH, 'annotation.csv'))\n",
    "new_annot = pd.read_csv(os.path.join(DATASET_PATH, 'annotation_updated.csv'))\n",
    "old_annot.shape, new_annot.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка данных для демонстрации"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_save = r'C:\\Users\\khanz\\PycharmProjects\\inno_ds\\final_project\\data\\demo'\n",
    "\n",
    "train_feature_description = {\n",
    "    # 'class': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, train_feature_description)\n",
    "\n",
    "\n",
    "image_paths, labels = [], []\n",
    "for data_type in ['test']:\n",
    "    files = glob.glob(flowers_tpu_cfg.images_path + f'/{data_type}/*.tfrec')\n",
    "    for i in tqdm(files, desc=f'{data_type}'):\n",
    "        train_image_dataset = tf.data.TFRecordDataset(i)\n",
    "        train_image_dataset = train_image_dataset.map(_parse_image_function)\n",
    "        ids = [str(id_features['id'].numpy())[2:-1] for id_features in train_image_dataset]\n",
    "        # labels.extend([int(class_features['class'].numpy()) for class_features in train_image_dataset])\n",
    "        images = [image_features['image'].numpy() for image_features in train_image_dataset]\n",
    "        for _id, img in zip(ids, images):\n",
    "            dst = os.path.join(path_to_save, f\"{_id}.jpeg\")\n",
    "            img = cv2.cvtColor(np.asarray(Image.open(io.BytesIO(img))), cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(dst, img)\n",
    "            image_paths.append('/'.join(dst.split('\\\\')[-2:]))\n",
    "\n",
    "df = pd.DataFrame(data={'path': image_paths})\n",
    "df.to_csv(os.path.join(path_to_save, 'annotation_demo.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
